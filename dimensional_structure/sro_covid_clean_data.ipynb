{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to clean training and test datasets \n",
    "\n",
    "* The procedure involves the following steps \n",
    "* load variables\n",
    "* transform with power transform \n",
    "* remove outliers \n",
    "* in the case of self-regulation variables only: remove correlated variables\n",
    "* save clean variables\n",
    "* impute variables \n",
    "* save imputed variabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selfregulation.utils.utils import get_info, get_admin_data, get_behav_data, get_recent_dataset,get_save_directory_train_test\n",
    "from selfregulation.utils.data_preparation_utils import  remove_correlated_task_variables, remove_outliers\n",
    "from selfregulation.utils.data_preparation_utils import  fit_transform_pt, transform_pt\n",
    "from selfregulation.utils.r_to_py_utils import missForest\n",
    "from selfregulation.utils.plot_utils import format_num\n",
    "import datetime\n",
    "from os import makedirs, path\n",
    "from math import ceil\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def clean_dataset(selected_var_pt = None, directory = None , suffix =  None):\n",
    "    #this wrapper function takes the transformed variables and \n",
    "    selected_var_pt_out   = remove_outliers(selected_var_pt) # remove outliers\n",
    "    selected_var_pt_clean = remove_correlated_task_variables(selected_var_pt_out) # remove correlated variables\n",
    "    return  selected_var_pt_out, selected_var_pt_clean \n",
    "\n",
    "def drop_not_common_vars(orig_data, common_vars = None): \n",
    "    drop_unique_vars = set(orig_data)-set(common_vars)\n",
    "    orig_data.drop(drop_unique_vars, axis=1, inplace = True)\n",
    "    return orig_data.sort_index(axis = 1)\n",
    "\n",
    "def get_missing_values_data(data): \n",
    "    percent_missing = (data.isnull().sum().sum()*100)/(data.shape[1]*data.shape[0])\n",
    "    print('Missing values: %', percent_missing.round(2))\n",
    "    \n",
    "    var_with_missing = np.sum(data.isnull().mean()>0)\n",
    "    var_with_no_missing = len(data.columns) - var_with_missing\n",
    "    \n",
    "    perc_var_no_missing = (var_with_no_missing)*100/(len(data.columns))\n",
    "    \n",
    "    print('Var without missing values: %', perc_var_no_missing.round(2))\n",
    "    \n",
    "    print('Var with missing values above 10%:')\n",
    "    missing  = data.isnull()\n",
    "    missing_high = missing.loc[:,missing.mean()>0.10]\n",
    "    print(missing_high.mean().sort_values(ascending=False))\n",
    "\n",
    "    \n",
    "    return percent_missing, perc_var_no_missing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/SRO/Data_master/Complete_02-16-2019\n",
      "/SRO/Data/Complete_Covid_03-26-2021\n"
     ]
    }
   ],
   "source": [
    "data_dir    = get_info('data_directory')\n",
    "dir_master  = get_save_directory_train_test('Data_master')\n",
    "dir_covid   = get_save_directory_train_test('Data')\n",
    "print(dir_master)\n",
    "print(dir_covid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean stress and mindset and psych variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "Cleaning this dataset\n",
      "Getting dataset: /SRO/Data/Complete_Covid_03-26-2021...:\n",
      "file: meaningful_variables_stress_mindset.csv \n",
      " \n",
      "**********************************************************************\n",
      "Training dataset\n",
      "**********************************************************************\n",
      "* Number of variables still skewed: 0\n",
      "* Successfully transformed 10 variables\n",
      "* 0 variables could not be transformed successfully\n",
      "Dropping 0 skewed data that could not be transformed successfully:\n",
      "\n",
      "**********************************************************************\n",
      "  missForest iteration\n",
      " \n",
      "1\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "2\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "*******************************************************************************\n",
      "Cleaning this dataset\n",
      "Getting dataset: /SRO/Data/Complete_Covid_03-26-2021...:\n",
      "file: meaningful_variables_psych.csv \n",
      " \n",
      "**********************************************************************\n",
      "Training dataset\n",
      "**********************************************************************\n",
      "* Number of variables still skewed: 0\n",
      "* Successfully transformed 9 variables\n",
      "* 0 variables could not be transformed successfully\n",
      "Dropping 0 skewed data that could not be transformed successfully:\n",
      "\n",
      "**********************************************************************\n",
      "  missForest iteration\n",
      " \n",
      "1\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "2\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "list_files =['meaningful_variables_stress_mindset', 'meaningful_variables_psych']\n",
    "\n",
    "for list_file in list_files: \n",
    "    file_name = list_file + '.csv'\n",
    "    \n",
    "    print('*' *79)\n",
    "    print('Cleaning this dataset')\n",
    "    selected_var                = get_behav_data(file = file_name, verbose=True)\n",
    "    vars_pt, pt                 = fit_transform_pt(selected_var, drop_failed=True )\n",
    "    vars_pt_clean               = remove_outliers(vars_pt)\n",
    "    vars_pt_clean.to_csv(path.join(dir_covid , list_file +'_pt_clean.csv'))\n",
    "\n",
    "    vars_pt_imputed, error = missForest(vars_pt_clean)\n",
    "    vars_pt_imputed.to_csv(path.join(dir_covid ,list_file+ '_pt_imputed.csv'))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean self regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting dataset: /SRO/Data/Complete_Covid_03-26-2021...:\n",
      "file: meaningful_variables.csv \n",
      " \n",
      "Getting dataset: /SRO/Data_master/Complete_02-16-2019...:\n",
      "file: meaningful_variables.csv \n",
      " \n"
     ]
    }
   ],
   "source": [
    "selected_var_covid_test  = get_behav_data(verbose=True)\n",
    "selected_var_master      = get_behav_data(data_subset = 'Data_master', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some variables from  master have different names, as different layout of survey was used\n",
    "#1.holt_laury_survey                             holt_laury_survey_correctlayout\n",
    "#2.selection_optimization_compensation_survey    selection_optimization_compensation_survey_correctlayout\n",
    "#3.sensation_seeking_survey                      sensation_seeking_survey_correctlayout\n",
    "selected_var_master.columns = [i.replace('holt_laury_survey', 'holt_laury_survey_correctlayout') for i in selected_var_master]\n",
    "selected_var_master.columns = [i.replace('selection_optimization_compensation_survey', 'selection_optimization_compensation_survey_correctlayout') for i in selected_var_master]\n",
    "selected_var_master.columns = [i.replace('sensation_seeking_survey', 'sensation_seeking_survey_correctlayout') for i in selected_var_master]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Split the master dataset to have subjects whose data were collected and analyzed only before onset covid(master, N = 386) and those whose data were collected and analyzed pre (master) and post (covid) onset COVID (N = 107)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_train_master   = get_admin_data(data_dir, 'sro_train_turkers_master.json')\n",
    "dict_test_master    = get_admin_data(data_dir, 'sro_test_turkers_master.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_master = list(dict_train_master.keys()) \n",
    "test_master  = list(dict_test_master.keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_master.sort()\n",
    "test_master.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subject for master training, those tested only once: 386\n",
      "Number of subject for master testing: 107\n"
     ]
    }
   ],
   "source": [
    "selected_var_master_train  = selected_var_master.loc[train_master ,:]\n",
    "selected_var_master_test   = selected_var_master.loc[test_master ,:]\n",
    "\n",
    "print(\"Number of subject for master training, those tested only once:\", len(selected_var_master_train.index))\n",
    "print(\"Number of subject for master testing:\", len(selected_var_master_test.index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(selected_var_master_train)== len(train_master), 'data has wrong number of subjects'\n",
    "assert train_master == list(selected_var_master_train.index),'data has wrong id subjects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(selected_var_master_test)== len(test_master), 'data has wrong number of subjects'\n",
    "assert test_master == list(selected_var_master_test.index),'data has wrong id subjects'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of meaningful variables, master train: 204\n",
      "Number of meaningful variables, master test: 204\n",
      "Number of meaningful variables, covid test: 204\n"
     ]
    }
   ],
   "source": [
    "print('Number of meaningful variables, master train:', len(selected_var_master_train.columns))\n",
    "print('Number of meaningful variables, master test:', len(selected_var_master_test.columns))\n",
    "print('Number of meaningful variables, covid test:', len( selected_var_covid_test.columns))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Transform variables with Power Transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "Training dataset\n",
      "**********************************************************************\n",
      "* Number of variables still skewed: 4\n",
      "* Successfully transformed 201 variables\n",
      "* 3 variables could not be transformed successfully\n",
      "Dropping 3 skewed data that could not be transformed successfully:\n",
      "bickel_titrator.hyp_discount_rate_medium\n",
      "bickel_titrator.hyp_discount_rate_small\n",
      "bickel_titrator.hyp_discount_rate_large\n",
      "**********************************************************************\n",
      "**********************************************************************\n",
      "Testing dataset\n",
      "**********************************************************************\n",
      "* Number of variables still skewed: 10\n",
      "* Successfully transformed 200 variables\n",
      "* 4 variables could not be transformed successfully\n",
      "Dropping 4 skewed data that could not be transformed successfully:\n",
      "bickel_titrator.hyp_discount_rate_medium\n",
      "bickel_titrator.hyp_discount_rate_small\n",
      "bickel_titrator.hyp_discount_rate_large\n",
      "kirby.hyp_discount_rate_large\n",
      "**********************************************************************\n",
      "**********************************************************************\n",
      "Testing dataset\n",
      "**********************************************************************\n",
      "* Number of variables still skewed: 13\n",
      "* Successfully transformed 196 variables\n",
      "* 8 variables could not be transformed successfully\n",
      "Dropping 8 skewed data that could not be transformed successfully:\n",
      "bickel_titrator.hyp_discount_rate_medium\n",
      "bickel_titrator.hyp_discount_rate_small\n",
      "bickel_titrator.hyp_discount_rate_large\n",
      "dickman_survey.dysfunctional\n",
      "kirby.hyp_discount_rate_medium\n",
      "kirby.hyp_discount_rate_small\n",
      "upps_impulsivity_survey.positive_urgency\n",
      "kirby.hyp_discount_rate_large\n",
      "**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "master_train_pt, pt  = fit_transform_pt(selected_var_master_train, drop_failed=True )\n",
    "master_test_pt       = transform_pt(pt, selected_var_master_test, drop_failed=True )\n",
    "covid_test_pt        = transform_pt(pt, selected_var_covid_test, drop_failed=True )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remove outliers and correlated variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Dropping 17 variables with correlations above 0.85\n",
      "**************************************************\n",
      "angling_risk_task_always_sunny.release_score.pt\n",
      "angling_risk_task_always_sunny.keep_score.pt\n",
      "holt_laury_survey_correctlayout.risk_aversion.pt\n",
      "kirby.percent_patient_small.pt\n",
      "kirby.percent_patient_medium.pt\n",
      "kirby.percent_patient_large.pt\n",
      "kirby.percent_patient.pt\n",
      "probabilistic_selection.value_sensitivity.pt\n",
      "stim_selective_stop_signal.hddm_thresh.pt\n",
      "stim_selective_stop_signal.hddm_drift.pt\n",
      "stim_selective_stop_signal.reactive_control_hddm_drift.pt\n",
      "stim_selective_stop_signal.hddm_non_decision.pt\n",
      "stim_selective_stop_signal.SSRT.pt\n",
      "tower_of_london.num_extra_moves.pt\n",
      "tower_of_london.planning_time.pt\n",
      "tower_of_london.num_optimal_solutions.pt\n",
      "tower_of_london.avg_move_time.pt\n",
      "**************************************************\n",
      "Dropping 15 variables with correlations above 0.85\n",
      "**************************************************\n",
      "angling_risk_task_always_sunny.release_score.pt\n",
      "angling_risk_task_always_sunny.keep_score.pt\n",
      "kirby.percent_patient_small.pt\n",
      "kirby.percent_patient_medium.pt\n",
      "kirby.percent_patient.pt\n",
      "probabilistic_selection.value_sensitivity.pt\n",
      "stim_selective_stop_signal.hddm_thresh.pt\n",
      "stim_selective_stop_signal.hddm_drift.pt\n",
      "stim_selective_stop_signal.reactive_control_hddm_drift.pt\n",
      "stim_selective_stop_signal.hddm_non_decision.pt\n",
      "stim_selective_stop_signal.SSRT.pt\n",
      "tower_of_london.num_extra_moves.pt\n",
      "tower_of_london.planning_time.pt\n",
      "tower_of_london.num_optimal_solutions.pt\n",
      "tower_of_london.avg_move_time.pt\n",
      "**************************************************\n",
      "Dropping 16 variables with correlations above 0.85\n",
      "**************************************************\n",
      "angling_risk_task_always_sunny.release_score.pt\n",
      "angling_risk_task_always_sunny.keep_score.pt\n",
      "cognitive_reflection_survey.intuitive_proportion.pt\n",
      "kirby.percent_patient_small.pt\n",
      "kirby.percent_patient_medium.pt\n",
      "kirby.percent_patient_large.pt\n",
      "probabilistic_selection.value_sensitivity.pt\n",
      "stim_selective_stop_signal.hddm_thresh.pt\n",
      "stim_selective_stop_signal.hddm_drift.pt\n",
      "stim_selective_stop_signal.reactive_control_hddm_drift.pt\n",
      "stim_selective_stop_signal.hddm_non_decision.pt\n",
      "stim_selective_stop_signal.SSRT.pt\n",
      "tower_of_london.num_extra_moves.pt\n",
      "tower_of_london.planning_time.pt\n",
      "tower_of_london.num_optimal_solutions.pt\n",
      "tower_of_london.avg_move_time.pt\n"
     ]
    }
   ],
   "source": [
    "master_train_pt_out, master_train_pt_clean = clean_dataset(selected_var_pt = master_train_pt)\n",
    "master_test_pt_out, master_test_pt_clean   = clean_dataset(selected_var_pt = master_test_pt)\n",
    "covid_test_pt_out, covid_test_pt_clean     = clean_dataset(selected_var_pt = covid_test_pt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keep only variables common to all three datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "common_vars = set.intersection(set(master_train_pt_clean), set(master_test_pt_clean),set(covid_test_pt_clean))\n",
    "master_train_pt_clean = drop_not_common_vars(master_train_pt_clean, common_vars)\n",
    "master_test_pt_clean  = drop_not_common_vars(master_test_pt_clean, common_vars)\n",
    "covid_test_pt_clean   = drop_not_common_vars(covid_test_pt_clean, common_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178\n",
      "178\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "print(len(master_train_pt_clean.columns))\n",
    "print(len(master_test_pt_clean.columns))\n",
    "print(len(covid_test_pt_clean.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save cleaned common variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_train_pt_clean.to_csv(path.join(dir_master , 'meaningful_variables_pt_clean_'  + 'train' + '.csv'))\n",
    "master_test_pt_clean.to_csv(path.join(dir_master ,  'meaningful_variables_pt_clean_'   + 'test' + '.csv'))\n",
    "covid_test_pt_clean.to_csv(path.join(dir_covid ,    'meaningful_variables_pt_clean_'   + 'test' + '.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Impute datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  missForest iteration\n",
      " \n",
      "1\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "2\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "3\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "4\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "5\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "1\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "2\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "3\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "4\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "1\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "2\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "3\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "4\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "5\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n",
      "  missForest iteration\n",
      " \n",
      "6\n",
      " \n",
      "in progress...\n",
      "done!\n",
      "\n"
     ]
    }
   ],
   "source": [
    "master_train_pt_imputed, error  = missForest(master_train_pt_clean)\n",
    "master_test_pt_imputed, error   = missForest(master_test_pt_clean)\n",
    "covid_test_pt_imputed, error    = missForest(covid_test_pt_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save imputed common variables**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_train_pt_imputed.to_csv(path.join(dir_master , 'meaningful_variables_pt_imputed_'  + 'train' + '.csv'))\n",
    "master_test_pt_imputed.to_csv(path.join(dir_master ,  'meaningful_variables_pt_imputed_'   + 'test' + '.csv'))\n",
    "covid_test_pt_imputed.to_csv(path.join(dir_covid ,    'meaningful_variables_pt_imputed_'   + 'test' + '.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******************************************************************************\n",
      "Master train\n",
      "Missing values: % 3.49\n",
      "Var without missing values: % 35.39\n",
      "Var with missing values above 10%:\n",
      "probabilistic_selection.positive_learning_bias.pt                                   0.334197\n",
      "motor_selective_stop_signal.hddm_non_decision.pt                                    0.318653\n",
      "motor_selective_stop_signal.hddm_thresh.pt                                          0.303109\n",
      "motor_selective_stop_signal.reactive_control_hddm_drift.pt                          0.300518\n",
      "motor_selective_stop_signal.proactive_control_hddm_drift.pt                         0.300518\n",
      "motor_selective_stop_signal.hddm_drift.pt                                           0.300518\n",
      "motor_selective_stop_signal.SSRT.pt                                                 0.300518\n",
      "discount_titrate.percent_patient.pt                                                 0.300518\n",
      "two_stage_decision.model_free.pt                                                    0.176166\n",
      "two_stage_decision.perseverance.pt                                                  0.173575\n",
      "two_stage_decision.model_based.pt                                                   0.173575\n",
      "selection_optimization_compensation_survey_correctlayout.loss_based_selection.pt    0.134715\n",
      "shift_task.model_beta.pt                                                            0.124352\n",
      "stop_signal.proactive_SSRT_speeding.pt                                              0.111399\n",
      "stop_signal.proactive_slowing_hddm_thresh.pt                                        0.108808\n",
      "stop_signal.SSRT_high.pt                                                            0.106218\n",
      "dtype: float64\n",
      "*******************************************************************************\n",
      "Master test\n",
      "Missing values: % 2.81\n",
      "Var without missing values: % 47.75\n",
      "Var with missing values above 10%:\n",
      "motor_selective_stop_signal.hddm_non_decision.pt               0.308411\n",
      "motor_selective_stop_signal.proactive_control_hddm_drift.pt    0.299065\n",
      "motor_selective_stop_signal.reactive_control_hddm_drift.pt     0.289720\n",
      "motor_selective_stop_signal.hddm_thresh.pt                     0.289720\n",
      "motor_selective_stop_signal.hddm_drift.pt                      0.289720\n",
      "motor_selective_stop_signal.SSRT.pt                            0.289720\n",
      "probabilistic_selection.positive_learning_bias.pt              0.261682\n",
      "discount_titrate.percent_patient.pt                            0.224299\n",
      "shift_task.model_beta.pt                                       0.140187\n",
      "two_stage_decision.model_free.pt                               0.130841\n",
      "stop_signal.proactive_SSRT_speeding.pt                         0.130841\n",
      "two_stage_decision.perseverance.pt                             0.112150\n",
      "two_stage_decision.model_based.pt                              0.112150\n",
      "stop_signal.hddm_non_decision.pt                               0.102804\n",
      "dtype: float64\n",
      "*******************************************************************************\n",
      "Covid test\n",
      "Missing values: % 2.0\n",
      "Var without missing values: % 63.48\n",
      "Var with missing values above 10%:\n",
      "motor_selective_stop_signal.hddm_non_decision.pt               0.308411\n",
      "motor_selective_stop_signal.hddm_drift.pt                      0.308411\n",
      "motor_selective_stop_signal.reactive_control_hddm_drift.pt     0.299065\n",
      "motor_selective_stop_signal.proactive_control_hddm_drift.pt    0.299065\n",
      "motor_selective_stop_signal.hddm_thresh.pt                     0.299065\n",
      "motor_selective_stop_signal.SSRT.pt                            0.299065\n",
      "discount_titrate.percent_patient.pt                            0.271028\n",
      "probabilistic_selection.positive_learning_bias.pt              0.196262\n",
      "shift_task.model_beta.pt                                       0.112150\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('*'*79)\n",
    "print('Master train')\n",
    "perc_missing, perc_var_no_missing= get_missing_values_data(master_train_pt_clean)\n",
    "print('*'*79)\n",
    "print('Master test')\n",
    "perc_missing, perc_var_no_missing=get_missing_values_data(master_test_pt_clean)\n",
    "print('*'*79)\n",
    "print('Covid test')\n",
    "perc_missing, perc_var_no_missing=get_missing_values_data(covid_test_pt_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
